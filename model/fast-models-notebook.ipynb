{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Prediction Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import gc  # Garbage collector for memory management\n",
    "import time\n",
    "import sys\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: (246945, 378)\n",
      "Number of symptom features: 377\n",
      "Number of unique diseases: 773\n",
      "Most common disease appears 1219 times\n",
      "Least common disease appears 1 times\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "# Change this path to match your file location\n",
    "symptoms_disease_df = pd.read_csv('Final_Augmented_dataset_Diseases_and_Symptoms.csv')\n",
    "print(f\"Dataset shape: {symptoms_disease_df.shape}\")\n",
    "\n",
    "# Identify disease column and symptoms\n",
    "disease_column = symptoms_disease_df.columns[0]\n",
    "symptom_columns = symptoms_disease_df.drop(disease_column, axis=1).columns\n",
    "\n",
    "print(f\"Number of symptom features: {len(symptom_columns)}\")\n",
    "print(f\"Number of unique diseases: {symptoms_disease_df[disease_column].nunique()}\")\n",
    "\n",
    "# Get counts of diseases to understand class distribution\n",
    "disease_counts = symptoms_disease_df[disease_column].value_counts()\n",
    "print(f\"Most common disease appears {disease_counts.max()} times\")\n",
    "print(f\"Least common disease appears {disease_counts.min()} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using top 300 most frequent symptoms out of 377\n",
      "Training set: (197556, 300), Test set: (49389, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the most frequent symptoms to reduce dimensionality\n",
    "symptom_counts = symptoms_disease_df[symptom_columns].sum().sort_values(ascending=False)\n",
    "top_symptoms = symptom_counts.head(300).index.tolist()\n",
    "print(f\"Using top {len(top_symptoms)} most frequent symptoms out of {len(symptom_columns)}\")\n",
    "\n",
    "# Create train/test datasets\n",
    "X = symptoms_disease_df[top_symptoms]  # Only use top symptoms\n",
    "y = symptoms_disease_df[disease_column]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# Free up memory\n",
    "del symptoms_disease_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define helper function for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_mb(obj):\n",
    "    \"\"\"Get approximate size of an object in MB\"\"\"\n",
    "    return sys.getsizeof(obj) / (1024 * 1024)\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train, evaluate and time a model\"\"\"\n",
    "    # Training\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Prediction time\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    predict_time = time.time() - start_time\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Summarize\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"  Training time: {train_time:.2f} seconds\")\n",
    "    print(f\"  Prediction time: {predict_time:.4f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"model\": model,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"train_time\": train_time,\n",
    "        \"predict_time\": predict_time,\n",
    "    }\n",
    "\n",
    "# Set up results storage\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree:\n",
      "  Accuracy: 0.0587 (5.87%)\n",
      "  Training time: 2.82 seconds\n",
      "  Prediction time: 0.1355 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Decision Tree\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=25,              # Deeper tree for better accuracy\n",
    "    min_samples_split=5,       # Avoid overfitting\n",
    "    min_samples_leaf=2,        # Avoid overfitting\n",
    "    class_weight='balanced',   # Handle class imbalance\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_results = evaluate_model(\"Decision Tree\", dt_model, X_train, y_train, X_test, y_test)\n",
    "results.append(dt_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Multinomial Naive Bayes...\n",
      "Multinomial Naive Bayes:\n",
      "  Accuracy: 0.8555 (85.55%)\n",
      "  Training time: 167.49 seconds\n",
      "  Prediction time: 0.2012 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Multinomial Naive Bayes\n",
    "nb_model = MultinomialNB(alpha=0.1)  # Lower alpha for this binary data\n",
    "\n",
    "nb_results = evaluate_model(\"Multinomial Naive Bayes\", nb_model, X_train, y_train, X_test, y_test)\n",
    "results.append(nb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training K-Nearest Neighbors...\n",
      "K-Nearest Neighbors:\n",
      "  Accuracy: 0.8138 (81.38%)\n",
      "  Training time: 0.21 seconds\n",
      "  Prediction time: 126.4341 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate KNN\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=5,      # Number of neighbors to consider\n",
    "    weights='distance',  # Weight by distance for better accuracy\n",
    "    algorithm='auto',    # Let sklearn choose the fastest algorithm\n",
    "    n_jobs=-1           # Use all cores\n",
    ")\n",
    "\n",
    "knn_results = evaluate_model(\"K-Nearest Neighbors\", knn_model, X_train, y_train, X_test, y_test)\n",
    "results.append(knn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SGD Classifier...\n",
      "SGD Classifier:\n",
      "  Accuracy: 0.8343 (83.43%)\n",
      "  Training time: 89.42 seconds\n",
      "  Prediction time: 0.2195 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate SGD Classifier\n",
    "sgd_model = SGDClassifier(\n",
    "    loss='log_loss',     # Logistic regression loss\n",
    "    penalty='l2',        # L2 regularization\n",
    "    alpha=0.0001,        # Regularization strength\n",
    "    max_iter=1000,       # Increased iterations for convergence\n",
    "    tol=1e-3,            # Tolerance for stopping criterion\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "sgd_results = evaluate_model(\"SGD Classifier\", sgd_model, X_train, y_train, X_test, y_test)\n",
    "results.append(sgd_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models sorted by accuracy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Prediction Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>85.55%</td>\n",
       "      <td>167.49 sec</td>\n",
       "      <td>0.2012 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD Classifier</th>\n",
       "      <td>83.43%</td>\n",
       "      <td>89.42 sec</td>\n",
       "      <td>0.2195 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>81.38%</td>\n",
       "      <td>0.21 sec</td>\n",
       "      <td>126.4341 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>5.87%</td>\n",
       "      <td>2.82 sec</td>\n",
       "      <td>0.1355 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy Training Time Prediction Time\n",
       "name                                                          \n",
       "Multinomial Naive Bayes   85.55%    167.49 sec      0.2012 sec\n",
       "SGD Classifier            83.43%     89.42 sec      0.2195 sec\n",
       "K-Nearest Neighbors       81.38%      0.21 sec    126.4341 sec\n",
       "Decision Tree              5.87%      2.82 sec      0.1355 sec"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame(results)\n",
    "comparison_df = comparison_df[['name', 'accuracy', 'train_time', 'predict_time']]\n",
    "comparison_df['accuracy'] = comparison_df['accuracy'] * 100  # Convert to percentage\n",
    "\n",
    "# Format for display\n",
    "display_df = comparison_df.copy()\n",
    "display_df['accuracy'] = display_df['accuracy'].map('{:.2f}%'.format)\n",
    "display_df['train_time'] = display_df['train_time'].map('{:.2f} sec'.format)\n",
    "display_df['predict_time'] = display_df['predict_time'].map('{:.4f} sec'.format)\n",
    "display_df.set_index('name', inplace=True)\n",
    "display_df.columns = ['Accuracy', 'Training Time', 'Prediction Time']\n",
    "\n",
    "# Display sorted by accuracy\n",
    "print(\"Models sorted by accuracy:\")\n",
    "display_df.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Select and analyze best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: Multinomial Naive Bayes\n",
      "Accuracy: 0.86%\n",
      "Training time: 167.49 seconds\n"
     ]
    }
   ],
   "source": [
    "# Find best model based on accuracy\n",
    "best_idx = comparison_df['accuracy'].idxmax()\n",
    "best_model_results = results[best_idx]\n",
    "best_model = best_model_results['model']\n",
    "best_model_name = best_model_results['name']\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_model_results['accuracy']:.2f}%\")\n",
    "print(f\"Training time: {best_model_results['train_time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Detailed Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for top 20 most common diseases: 0.8456 (84.56%)\n",
      "\n",
      "Detailed metrics for the best model:\n",
      "Weighted average precision: 0.8626\n",
      "Weighted average recall:    0.8555\n",
      "Weighted average F1-score:  0.8536\n"
     ]
    }
   ],
   "source": [
    "# Predict with best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy for top diseases\n",
    "top_disease_counts = y.value_counts().head(20)\n",
    "top_diseases = top_disease_counts.index\n",
    "mask = y_test.isin(top_diseases)\n",
    "\n",
    "if mask.sum() > 0:\n",
    "    top_accuracy = accuracy_score(y_test[mask], y_pred[mask])\n",
    "    print(f\"\\nAccuracy for top 20 most common diseases: {top_accuracy:.4f} ({top_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Get summary metrics\n",
    "print(\"\\nDetailed metrics for the best model:\")\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "print(f\"Weighted average precision: {report_dict['weighted avg']['precision']:.4f}\")\n",
    "print(f\"Weighted average recall:    {report_dict['weighted avg']['recall']:.4f}\")\n",
    "print(f\"Weighted average F1-score:  {report_dict['weighted avg']['f1-score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Create prediction function for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example predictions with the best model:\n",
      "\n",
      "Case 1: Patient with symptoms: headache, fever, cough\n",
      "  Predicted disease: acute bronchitis\n",
      "  Top predictions:\n",
      "    1. acute bronchitis (Confidence: 0.1051)\n",
      "    2. chronic sinusitis (Confidence: 0.0997)\n",
      "    3. flu (Confidence: 0.0964)\n",
      "\n",
      "Case 2: Patient with symptoms: sharp abdominal pain, nausea, vomiting\n",
      "  Predicted disease: pyelonephritis\n",
      "  Top predictions:\n",
      "    1. pyelonephritis (Confidence: 0.0335)\n",
      "    2. gastrointestinal hemorrhage (Confidence: 0.0309)\n",
      "    3. fluid overload (Confidence: 0.0304)\n",
      "\n",
      "Case 3: Patient with symptoms: back pain, shortness of breath, dizziness\n",
      "  Predicted disease: magnesium deficiency\n",
      "  Top predictions:\n",
      "    1. magnesium deficiency (Confidence: 0.0648)\n",
      "    2. myasthenia gravis (Confidence: 0.0511)\n",
      "    3. poisoning due to gas (Confidence: 0.0496)\n"
     ]
    }
   ],
   "source": [
    "def predict_disease(symptoms_input, model, feature_list):\n",
    "    \"\"\"Create a prediction for given symptoms\"\"\"\n",
    "    # Create input dataframe with zeros\n",
    "    input_data = pd.DataFrame(0, index=[0], columns=feature_list)\n",
    "    \n",
    "    # Set symptoms that are present\n",
    "    matched_symptoms = []\n",
    "    for symptom in symptoms_input:\n",
    "        if symptom in input_data.columns:\n",
    "            input_data[symptom] = 1\n",
    "            matched_symptoms.append(symptom)\n",
    "    \n",
    "    # Check if any symptoms matched\n",
    "    if not matched_symptoms:\n",
    "        return \"No matching symptoms found in the model's feature set\", [], []\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_disease = model.predict(input_data)[0]\n",
    "    \n",
    "    # Get probabilities if available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(input_data)[0]\n",
    "        top_indices = probabilities.argsort()[-3:][::-1]\n",
    "        top_diseases = [model.classes_[i] for i in top_indices]\n",
    "        top_probs = [probabilities[i] for i in top_indices]\n",
    "        return predicted_disease, top_diseases, top_probs\n",
    "    \n",
    "    # For models that don't have predict_proba\n",
    "    return predicted_disease, [predicted_disease], [1.0]\n",
    "\n",
    "# Test the prediction function\n",
    "test_cases = [\n",
    "    ['headache', 'fever', 'cough'],\n",
    "    ['sharp abdominal pain', 'nausea', 'vomiting'],\n",
    "    ['back pain', 'shortness of breath', 'dizziness']\n",
    "]\n",
    "\n",
    "print(\"\\nExample predictions with the best model:\")\n",
    "for i, symptoms in enumerate(test_cases):\n",
    "    print(f\"\\nCase {i+1}: Patient with symptoms: {', '.join(symptoms)}\")\n",
    "    try:\n",
    "        predicted_disease, top_diseases, top_probs = predict_disease(symptoms, best_model, top_symptoms)\n",
    "        \n",
    "        if isinstance(predicted_disease, str) and predicted_disease.startswith(\"No matching\"):\n",
    "            print(f\"  {predicted_disease}\")\n",
    "        else:\n",
    "            print(f\"  Predicted disease: {predicted_disease}\")\n",
    "            print(\"  Top predictions:\")\n",
    "            for j, (disease, prob) in enumerate(zip(top_diseases, top_probs)):\n",
    "                if hasattr(best_model, 'predict_proba'):\n",
    "                    print(f\"    {j+1}. {disease} (Confidence: {prob:.4f})\")\n",
    "                else:\n",
    "                    print(f\"    {j+1}. {disease}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error in prediction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the best model (Multinomial Naive Bayes)...\n",
      "Model saved successfully\n",
      "\n",
      "Saving the fastest good model (K-Nearest Neighbors)...\n",
      "Fast model saved successfully\n",
      "Feature list saved as 'model_features.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "print(f\"\\nSaving the best model ({best_model_name})...\")\n",
    "joblib.dump(best_model, f'disease_prediction_{best_model_name.lower().replace(\" \", \"_\")}.joblib', compress=9)\n",
    "print(f\"Model saved successfully\")\n",
    "\n",
    "# Also save the fastest good model if different\n",
    "if fastest_model_results['name'] != best_model_name:\n",
    "    fastest_model = fastest_model_results['model']\n",
    "    print(f\"\\nSaving the fastest good model ({fastest_model_results['name']})...\")\n",
    "    joblib.dump(fastest_model, f'disease_prediction_{fastest_model_results[\"name\"].lower().replace(\" \", \"_\")}.joblib', compress=9)\n",
    "    print(f\"Fast model saved successfully\")\n",
    "\n",
    "# Save the feature list\n",
    "pd.Series(top_symptoms).to_csv('model_features.csv', index=False, header=['feature'])\n",
    "print(\"Feature list saved as 'model_features.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model loading...\n",
      "Model loaded successfully in 0.01 seconds\n",
      "Test prediction: gastritis\n"
     ]
    }
   ],
   "source": [
    "# Clear memory\n",
    "del best_model\n",
    "if 'fastest_model' in locals():\n",
    "    del fastest_model\n",
    "gc.collect()\n",
    "\n",
    "# Test loading the best model\n",
    "print(f\"\\nTesting model loading...\")\n",
    "start_time = time.time()\n",
    "model_file = f'disease_prediction_{best_model_name.lower().replace(\" \", \"_\")}.joblib'\n",
    "loaded_model = joblib.load(model_file)\n",
    "load_time = time.time() - start_time\n",
    "\n",
    "print(f\"Model loaded successfully in {load_time:.2f} seconds\")\n",
    "\n",
    "# Verify predictions work\n",
    "test_input = pd.DataFrame(0, index=[0], columns=top_symptoms)\n",
    "test_input.iloc[0, 0:3] = 1  # Set first three symptoms to 1\n",
    "prediction = loaded_model.predict(test_input)[0]\n",
    "print(f\"Test prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS7180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
